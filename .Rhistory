# library(xlsx)
###############################set working dir###############################
# setwd("C:/Users/Chinmay/Downloads/attachments/")
###############################Load Data###############################
wb <- loadWorkbook("C:/Chinmay/mika_09_12_2017/data/MicaCreek_nutrientdata_thruMay2017_20170829_dwloaded_10_12_17.xlsx")
lst <- readWorksheet(wb, sheet = getSheets(wb))
NOx <-lst$`NO3+NO2`
NOx<- subset(NOx, select = c(1:9))
TKN<- lst$TKN
TKN<- subset(TKN, select = c(1:9))
TN<- lst$TN
TN<- subset(TN, select = c(1:9))
NH3<- lst$`NH3(TAN)`
NH3<- subset(NH3, select = c(1:9))
TP<- lst$TP
TP<- subset(TP, select= c(1:9))
OP<- lst$OP
OP<- subset(OP, select = c(1:9))
ldsat<-loadWorkbook("C:/Chinmay/mika_09_12_2017/analysis_output/Percent_forest_cover_Landsat/zonalstats_all_wsheds.xlsx")
ndvi <- readWorksheet(ldsat, sheet = 'sheet1')
ndvi<- subset(ndvi, select = c(1:8))
View(ndvi)
#merge datasets based on common date
NOx_mergedfile = merge(NOx, ndvi, by='Month')
TKN_mergedfile = merge(TKN, ndvi, by='Month')
TN_mergedfile = merge(TN, ndvi, by='Month')
NH3_mergedfile = merge(NH3, ndvi, by='Month')
TP_mergedfile = merge(TP, ndvi, by='Month')
OP_mergedfile = merge(OP, ndvi, by='Month')
sheets<- list('NOx'=NOx_mergedfile, 'TKN'=TKN_mergedfile, 'TN'= TN_mergedfile, 'NH3(TAN)'= NH3_mergedfile, 'TP'= TP_mergedfile, 'OP'= OP_mergedfile)
library(writexl)
write_xlsx(sheets, "C:/Chinmay/mika_09_12_2017/data/Percent_landsatNDVI_nutirent_data.xlsx")
source('C:/Chinmay/mika_09_12_2017/scripts/R/merge_workbooks_by_common_column.R')
###############################clear environment and console###############################
rm(list = ls())
cat("\014")
###############################Load required packages###############################
library(ggplot2)
library(XLConnect)
# library(xlsx)
###############################set working dir###############################
# setwd("C:/Users/Chinmay/Downloads/attachments/")
###############################Load Data###############################
wb <- loadWorkbook("C:/Chinmay/mika_09_12_2017/data/MicaCreek_nutrientdata_thruMay2017_20170829_dwloaded_10_12_17.xlsx")
lst <- readWorksheet(wb, sheet = getSheets(wb))
NOx <-lst$`NO3+NO2`
NOx<- subset(NOx, select = c(1:9))
TKN<- lst$TKN
TKN<- subset(TKN, select = c(1:9))
TN<- lst$TN
TN<- subset(TN, select = c(1:9))
NH3<- lst$`NH3(TAN)`
NH3<- subset(NH3, select = c(1:9))
TP<- lst$TP
TP<- subset(TP, select= c(1:9))
OP<- lst$OP
OP<- subset(OP, select = c(1:9))
ldsat<-loadWorkbook("C:/Chinmay/mika_09_12_2017/analysis_output/Percent_forest_cover_MODIS/Percent_f_cover_all_wsheds.xlsx")
ndvi <- readWorksheet(ldsat, sheet = 'monthly_values')
View(ndvi)
ndvi<- subset(ndvi, select = c(5:12))
View(ndvi)
View(NOx)
View(NH3)
source('C:/Chinmay/mika_09_12_2017/scripts/R/merge_workbooks_by_common_column.R')
###############################clear environment and console###############################
rm(list = ls())
cat("\014")
###############################Load required packages###############################
library(ggplot2)
library(XLConnect)
# library(xlsx)
###############################set working dir###############################
# setwd("C:/Users/Chinmay/Downloads/attachments/")
###############################Load Data###############################
wb <- loadWorkbook("C:/Chinmay/mika_09_12_2017/data/MicaCreek_nutrientdata_thruMay2017_20170829_dwloaded_10_12_17.xlsx")
lst <- readWorksheet(wb, sheet = getSheets(wb))
NOx <-lst$`NO3+NO2`
NOx<- subset(NOx, select = c(1:9))
TKN<- lst$TKN
TKN<- subset(TKN, select = c(1:9))
TN<- lst$TN
TN<- subset(TN, select = c(1:9))
NH3<- lst$`NH3(TAN)`
NH3<- subset(NH3, select = c(1:9))
TP<- lst$TP
TP<- subset(TP, select= c(1:9))
OP<- lst$OP
OP<- subset(OP, select = c(1:9))
ldsat<-loadWorkbook("C:/Chinmay/mika_09_12_2017/analysis_output/Percent_forest_cover_MODIS/Percent_f_cover_all_wsheds.xlsx")
ndvi <- readWorksheet(ldsat, sheet = 'monthly_values')
ndvi<- subset(ndvi, select = c(5:12))
#merge datasets based on common date
NOx_mergedfile = merge(NOx, ndvi, by='Month')
TKN_mergedfile = merge(TKN, ndvi, by='Month')
TN_mergedfile = merge(TN, ndvi, by='Month')
NH3_mergedfile = merge(NH3, ndvi, by='Month')
TP_mergedfile = merge(TP, ndvi, by='Month')
OP_mergedfile = merge(OP, ndvi, by='Month')
sheets<- list('NOx'=NOx_mergedfile, 'TKN'=TKN_mergedfile, 'TN'= TN_mergedfile, 'NH3(TAN)'= NH3_mergedfile, 'TP'= TP_mergedfile, 'OP'= OP_mergedfile)
library(writexl)
write_xlsx(sheets, "C:/Chinmay/mika_09_12_2017/data/Percent_MODISNDVI_nutirent_data.xlsx")
library(rloadest)
library(rloadest)
library(survival)
Sample <- eList$Sample
Sample <- Sample[!duplicated(Sample$Date),]
library(EGRET)
site <- "05427718"
pCode <- "00665"
Sample <- readNWISSample(site, pCode, "1990-01-01","2016-01-01")
Daily <- readNWISDaily(site,"00060", "1990-01-01","2016-01-01")
INFO <- readNWISInfo(site,pCode,interactive = FALSE)
eList <- mergeReport(INFO,Daily,Sample)
eList <- modelEstimation(eList)
Sample <- eList$Sample
sample
Sample
Sample <- Sample[!duplicated(Sample$Date),]
Sample
head(Sample)
?loadReg()
loadestModel <- loadReg(Surv(ConcLow, ConcHigh, type="interval2")
~ model(0),
data = Sample,
flow = "Q", dates = "Date",
flow.units="cms",
conc.units="mg/l",
station=eList$INFO$station.nm)
loadestModel <- loadReg(Surv(ConcLow, ConcHigh, type="interval2")
~ model(1),
data = Sample,
flow = "Q", dates = "Date",
flow.units="cms",
conc.units="mg/l",
station=eList$INFO$station.nm)
loadestModel <- loadReg(Surv(ConcLow, ConcHigh, type="interval2")
~ model(9),
data = Sample,
flow = "Q", dates = "Date",
flow.units="cms",
conc.units="mg/l",
station=eList$INFO$station.nm)
View(loadestModel)
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
#clear environment
rm(list = ls())
#clear console
cat("\014")
#import libraries
library(maptools)
library(raster)
library(rgdal)
#path to rasters and shapefile
grids <- list.files("C:/Chinmay/bda/Mica_whsed_landsat/NDVI/NDVI_tiles", pattern = "*.TIF$")
source('~/.active-rstudio-document')
s<- stack(grids)
source('~/.active-rstudio-document')
for (i in 1:length(r)) {
name<- r[i]  ###save the name of original landsat tiff
char1<-substr(r[i],10,16)}
#clear environment
rm(list = ls())
#clear console
cat("\014")
#import libraries
library(maptools)
library(raster)
library(rgdal)
#path to rasters and shapefile
r <- list.files("C:/Chinmay/mika_09_12_2017/data/Mica_whsed_landsat/NDVI/NDVI_tiles", pattern = "*.TIF$")
poly <- readOGR("C:/Chinmay/mika_09_12_2017/data/mika_shapefiles/wsheds30mwgs84_UTM11N.shp")
for (i in 1:length(r)) {
name<- r[i]  ###save the name of original landsat tiff
char1<-substr(r[i],10,16)}
for (i in 1:length(r)) {
name<- r[i]  ###save the name of original landsat tiff
char1<-substr(r[i],1,11)}
for (i in 1:length(r)) {
name<- r[i]  ###save the name of original landsat tiff
char1<-substr(r[i],1,11)
char2<-substr(r[i],12,15)}
for (i in 1:length(r)) {
name<- r[i]  ###save the name of original landsat tiff
char1<-substr(r[i],1,11)
char2<-substr(r[i],12,15)
name<-paste(char1,char2,sep="")}
for (i in 1:length(r)) {
name<- r[i]  ###save the name of original landsat tiff
char1<-substr(r[i],1,11)
char2<-substr(r[i],12,15)
name<-paste(char1,char2,sep="")
band<- raster(r[i])}
r
crs<- crs(raster(r[1]))
###load shapefile used to clip landsat scenes
AOI<- readOGR(".","AOI")
plot(AOI)
my.proj<- crs(AOI)
my.proj
r
crs<- crs(raster(r[1]))
#clear environment
rm(list = ls())
#clear console
cat("\014")
#import libraries
library(maptools)
library(raster)
library(rgdal)
#path to rasters and shapefile
r <- list.files("C:/Chinmay/mika_09_12_2017/data/Mica_whsed_landsat/clipped_to_MCEW_NDVI", pattern = "*.TIF$")
poly <- readOGR("C:/Chinmay/mika_09_12_2017/data/mika_shapefiles/wsheds30mwgs84_UTM11N.shp")
#clear environment
rm(list = ls())
#clear console
cat("\014")
#import libraries
library(maptools)
library(raster)
library(rgdal)
#path to rasters and shapefile
r <- list.files("C:/Chinmay/mika_09_12_2017/data/Mica_whsed_landsat/clipped_to_MCEW_NDVI", pattern = "*.tif$")
poly <- readOGR("C:/Chinmay/mika_09_12_2017/data/mika_shapefiles/wsheds30mwgs84_UTM11N.shp")
#create a raster stack from the list
rastStack <- stack(r)
source('~/.active-rstudio-document')
#path to rasters and shapefile
tifPath <- file.path("C:/Chinmay/mika_09_12_2017/data/Mica_whsed_landsat/clipped_to_MCEW_NDVI")
#open up the cropped files
#create list of files to make raster stack
allCropped <-  list.files(tifPath, full.names=TRUE, pattern = ".tif$")
poly <- readOGR("C:/Chinmay/mika_09_12_2017/data/mika_shapefiles/wsheds30mwgs84_UTM11N.shp")
#create a raster stack from the list
rastStack <- stack(allCropped)
install.packages("animation")
source('C:/Users/deva4998/Desktop/tiff_to_gif.R')
source('C:/Users/deva4998/Desktop/tiff_to_gif.R')
source('C:/Users/deva4998/Desktop/tiff_to_gif.R')
install.packages("install.packages("magick")")
install.packages("magick")
source('C:/Users/deva4998/Desktop/tiff_to_gif.R')
source('C:/Users/deva4998/Desktop/tiff_to_gif.R')
source('C:/Users/deva4998/Desktop/tiff_to_gif.R')
source('C:/Users/deva4998/Desktop/tiff_to_gif.R')
animate(rastStack)
brick(allCropped)
saveGIF(animate(rastStack),movie.name = 'temp.gif',
ani.width = 300, ani.height = 300)
library(installr); install.ImageMagick(URL = "http://www.imagemagick.org/script/binary-releases.php")
install.imagemagick("https://www.imagemagick.org/script/download.php")
source('C:/Users/deva4998/Desktop/tiff_to_gif.R')
source('C:/Users/deva4998/Desktop/tiff_to_gif.R')
#clear environment
rm(list = ls())
#clear console
cat("\014")
#import libraries
library(maptools)
library(raster)
library(rgdal)
library(animation)
#path to rasters and shapefile
tifPath <- file.path("C:/Chinmay/mika_09_12_2017/data/Mica_whsed_landsat/test")
#open up the cropped files
#create list of files to make raster stack
allCropped <-  list.files(tifPath, full.names=TRUE, pattern = ".tif$")
# read ploygon shapefile
poly <- readOGR("C:/Chinmay/mika_09_12_2017/data/mika_shapefiles/wsheds30mwgs84_UTM11N.shp")
#create a raster stack from the list
rastStack <- stack(allCropped)
library(animation)
a<- animate(rastStack)
a
saveGIF(animate(rastStack), "temp.gif")
source('C:/Users/deva4998/Desktop/tiff_to_gif.R')
animate(rastStack)
animate(rastStack)
animate(rastStack,pause=0.50)
animate(rastStack,pause=1)
install.packages("gganimate")
animate(rastStack,pause=1)+ plot(ploy, add=TRUE)
source('C:/Users/deva4998/Desktop/tiff_to_gif.R')
#if(!file.exists(path_gif)) { # Check if the file exists
saveMovie(
for (i in 1:length(allCropped)) {
plot(rastStack[[i]],
main=names(rastStack[[i]]),
legend.lab="NDVI",
col=rev(terrain.colors(30))
)
},
movie.name = 'temp.gif',
ani.width = 300, ani.height = 300,
interval=.5, ani.options(convert = 'C:/Program Files/ImageMagick-7.0.7-Q16/magick.exe'))
source('C:/Users/deva4998/Desktop/tiff_to_gif.R')
library(animation)
source('C:/Users/deva4998/Desktop/tiff_to_gif.R')
source('C:/Users/deva4998/Desktop/tiff_to_gif.R')
source('C:/Users/deva4998/Desktop/tiff_to_gif.R')
source('C:/Users/deva4998/Desktop/tiff_to_gif.R')
source('C:/Users/deva4998/Desktop/tiff_to_gif.R')
source('C:/Users/deva4998/Desktop/tiff_to_gif.R')
source('C:/Users/deva4998/Desktop/tiff_to_gif.R')
source('C:/Users/deva4998/Desktop/tiff_to_gif.R')
source('C:/Users/deva4998/Desktop/tiff_to_gif.R')
source('C:/Users/deva4998/Desktop/tiff_to_gif.R')
data(trees)
data(ChickWeight)
head(trees)
head(ChickWeight)
library(snotelr)
snotel.explorer()
a<-download.snotel(site = 623)
snotel.info(path = ".")
data = snotel.info(path = NULL)
download.snotel(site = 623)
a<-download.snotel(site = 623)
data
tidy(mg)
# let's simulate the data the explanatory variables: temperature (x1),
# precipitation (x2) and the treatment (1=Control, 2= N addition)
set.seed(1)
x1 <- rnorm(100, 10, 2)
x2 <- rnorm(100, 100, 10)
modmat <- model.matrix(~x1 + x2, data = data.frame(x1, x2))
vector of fixed effect
betas <- c(10, 2, 0.2, 3)
vector of fixed effect
betas <- c(10, 2, 0.2)
betas <- c(10, 2, 0.2)
y <- rnorm(n = 100, mean = modmat %*% betas, sd = 1)
# first model
m <- lm(y ~ x1 + x2)
m$coefficients[1]
m$coefficients[2]
summary(m)
install.packages("dataone")
install.packages("dataone")
library (dataone)
cn <- CNode("PROD")
mn <- getMNode(cn, "urn:node:KNB")
library(XML)
metadata <- rawToChar(getObject(mn, id))
doc = xmlRoot(xmlTreeParse(metadata, asText=TRUE, trim = TRUE, ignoreBlanks = TRUE))
tf <- tempfile()
saveXML(doc, tf)
file.show(tf)
library(dataone)
cn <- CNode("PROD")
mn <- getMNode(cn, "urn:node:KNB")
mySearchTerms <- list(q="abstract:salmon+AND+keywords:spawn+AND+keywords:chinook",
fl="id,title,dateUploaded,abstract,size",
fq="dateUploaded:[2017-06-01T00:00:00.000Z TO 2017-07-01T00:00:00.000Z]",
sort="dateUploaded+desc")
result <- query(mn, solrQuery=mySearchTerms, as="data.frame")
result[1,c("id", "title")]
id <- result[1,'id']
cn <- CNode("PROD")
mn <- getMNode(cn, "urn:node:LTER")
mn
qy <- dataone::query(cn, list(
rows = "300",
q    = "title:*stream chemistry*",
fq   = "(title:*streamflow*)",
fl   = "id,title,dateModified"),
as = "data.frame"))
qy <- dataone::query(cn, list(
rows = "300",
q    = "title:*stream*",
fq   = "(title:*streamflow*)",
fl   = "id,title,dateModified"),
as = "data.frame"))
qy <- dataone::query(cn, list(
rows = "300",
q    = "title:*stream*",
fq   = "(title:*streamflow*)",
fl   = "id,title,dateModified"),
as = "data.frame")
qy
library(dplyr)
qy <- slice(qy, grep("^doi", id, invert = TRUE)))
qy <- slice(qy, grep("^doi", id, invert = TRUE))
qy
qy <- arrange(qy, desc(id), desc(dateModified))
qy
library(dplyr)
library(datone)
qy <- dataone::query(cn, list(
rows = "300",
q    = "title:*stream chemistry*",
fq   = "(title:*streamflow*)",
fl   = "id,title,dateModified"),
as = "data.frame"))
qy <- slice(qy, grep("^doi", id, invert = TRUE)))
qy <- arrange(qy, desc(id), desc(dateModified))
library(dplyr)
library(datone)
qy <- dataone::query(cn, list(
rows = "300",
q    = "title:*stream chemistry*",
fq   = "(title:*streamflow*)",
fl   = "id,title,dateModified"),
as = "data.frame"))
qy <- slice(qy, grep("^doi", id, invert = TRUE))
qy <- arrange(qy, desc(id), desc(dateModified))
qy
typeof(qy)
yy[20]
qy[20]
qy[20:]
qy[:, 1]
tail(qy)
mySearchTerms <- list(q="https://portal.edirepository.org:443/nis/simpleSearch?defType=edismax&q=*:*&fq=scope:(knb-lter-and)&fq=-scope:ecotrends&fq=-scope:lter-landsat*&fl=id,packageid,title,author,organization,pubdate,coordinates&debug=false",
fl="id,packageid,title,author,organization,pubdate,coordinates&debug=false",
fq="dateUploaded:[2017-06-01T00:00:00.000Z TO 2017-07-01T00:00:00.000Z]",
sort="dateUploaded+desc")
mySearchTerms
mySearchTerms <- list(q="https://portal.edirepository.org:443/nis/simpleSearch?defType=edismax&q=*:*&fq=scope:(knb-lter-and)&fq=-scope:ecotrends&fq=-scope:lter-landsat*&fl=id,packageid,title,author,organization,pubdate,coordinates&debug=false",
fl="id,packageid,title,author,organization,pubdate,coordinates&debug=false",
fq="dateUploaded:[2017-06-01T00:00:00.000Z TO 2017-07-01T00:00:00.000Z]",
sort="dateUploaded+desc")
result <- query(mn, solrQuery=mySearchTerms, as="data.frame")
dataRaw <- getObject(mn, "knb-lter-hbr.1")
id
library(dplyr)
library(datone)
qy <- dataone::query(cn, list(
rows = "300",
q    = "title:*stream chemistry*",
fq   = "(title:*streamflow*)",
fl   = "id,title,dateModified"),
as = "data.frame"))
qy <- slice(qy, grep("^doi", id, invert = TRUE))
qy <- arrange(qy, desc(id), desc(dateModified))
i
id
title
print(qy)
qy[20:, :]
qy[20, :]
qy[20]
qy[:3]
qy[2]
qy[1]
qy[0]
qy[2]
qy[3]
qy[3][1]
qy[3][20]
qy[3]
View(qy)
View(qy)
library(dplyr)
library(datone)
qy <- dataone::query(cn, list(
rows = "300",
q    = "title:*streamflow*",
fq   = "(title:*chemistry*)",
fl   = "id,title,dateModified"),
as = "data.frame"))
qy <- slice(qy, grep("^doi", id, invert = TRUE))
qy <- arrange(qy, desc(id), desc(dateModified))
library(dplyr)
library(datone)
qy <- dataone::query(cn, list(
rows = "300",
q    = "title:*streamflow*",
fq   = "(title:*streamflow*)",
fl   = "id,title,dateModified"),
as = "data.frame"))
qy <- slice(qy, grep("^doi", id, invert = TRUE))
qy <- arrange(qy, desc(id), desc(dateModified))
library(dataone)
install.packages("installr")
library(installr)
updateR()
install.packages("devtools")
install.packages("roxygen2")
install.packages("devtools")
library("devtools")
devtools::install_github("klutometis/roxygen")
library(roxygen2)
setwd(C:\Chinmay\Github)
setwd(C:/Chinmay/Github)
setwd("C:/Chinmay/Github")
devtools::create("Sorption")
getwd
getwd()
setwd("./Sorption")
getwd()
document()
document()
document()
document()
document()
devtools::load_all(".")
library(Sorption)
nstall.Rtools()
install.Rtools()
library(Sorption)
devtools::load_all(".")
devtools::load_all(".")
library(Sorption)
library(Sorption)
devtools::load_all(".")
library(Sorption)
library(Sorption)
library("Sorption", lib.loc="~/R/win-library/3.5")
?LangmuirParameters
detach("package:Sorption", unload=TRUE)
